{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-BiLSTM-CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on the work of \"End-to-end Sequence Labelling via Bidirectional LSTM-CNNs-CRF https://arxiv.org/pdf/1603.01354.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECENT UPDATE: Currently working on writing a custom training loop in order to define early stopping condition on F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/thevindegamboda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras import layers # Just for example, delete later\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import LSTM, concatenate, Embedding, Dense, TimeDistributed, InputSpec, Dropout, Bidirectional, Layer, Conv1D, SpatialDropout1D,GlobalMaxPooling1D, Concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow_addons.text import crf_decode, crf_log_likelihood\n",
    "\n",
    "# from keras_contrib.losses import crf_loss\n",
    "# from keras_contrib.metrics import crf_accuracy\n",
    "\n",
    "from tf2crf import CRF, ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    file = open(file_path, \"r\")\n",
    "    data, entities, sentence, unique_labels = [], [], [], []\n",
    "    for line in file:\n",
    "        line = line.strip(\"\\n\").split(\"\\t\")\n",
    "        \n",
    "        if len(line) > 1:\n",
    "            word = line[0]\n",
    "            label = line[1]\n",
    "            \n",
    "            sentence.append(word)\n",
    "            entities.append(label)\n",
    "            \n",
    "            if label not in unique_labels:\n",
    "                unique_labels.append(label)\n",
    "            \n",
    "        elif len(entities) > 0:\n",
    "            sentence = \" \".join(sentence)\n",
    "            data.append({\"sentence\" : sentence, \"entities\" : entities})\n",
    "            entities, sentence = [], []\n",
    "            \n",
    "    file.close()\n",
    "    return data, unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_filepath = \"../data/NERdata/NCBI-disease/train_dev.tsv\"\n",
    "test_filepath = \"../data/NERdata/NCBI-disease/test.tsv\"\n",
    "\n",
    "train_data, train_unq_labels = load_data(train_dev_filepath)\n",
    "test_data, _ = load_data(test_filepath)\n",
    "\n",
    "data = train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Identification of APC2 , a homologue of the adenomatous polyposis coli tumour suppressor .',\n",
       " 'entities': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B',\n",
       "  'I',\n",
       "  'I',\n",
       "  'I',\n",
       "  'O',\n",
       "  'O']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7287, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how many datapoints and unique labels we have acquired from the dataset\n",
    "\n",
    "len(data), len(train_unq_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will make reference dictionaries for the text elements\n",
    "\n",
    "def get_mappings(data, word_ent):\n",
    "\n",
    "    if word_ent == \"word\" or word_ent == \"char\":\n",
    "        vocab = Counter([i for x in data for i in x['sentence'].split()])\n",
    "        if word_ent == \"char\":\n",
    "            vocab = Counter([i for x in vocab for i in list(x)])\n",
    "    elif word_ent == \"ent\":\n",
    "        vocab = Counter([i for x in data for i in x['entities']])\n",
    "    \n",
    "    vocab = [i[0] for i in vocab.most_common()]\n",
    "    \n",
    "    idx2tok = {idx:tok for idx, tok in enumerate(vocab, 1)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab, 1)}\n",
    "    \n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "word2idx, idx2word = get_mappings(data, \"word\")\n",
    "char2idx, idx2char = get_mappings(data, \"char\")\n",
    "tag2idx, idx2tag = get_mappings(data, \"ent\")\n",
    "\n",
    "n_words = len(word2idx)\n",
    "n_chars = len(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will add a PAD token to consider padding during training\n",
    "\n",
    "word2idx[\"UNK\"] = n_words + 1\n",
    "idx2word[n_words + 1] = \"UNK\"\n",
    "\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word[0] = \"PAD\"\n",
    "\n",
    "char2idx[\"UNK\"] = n_chars + 1\n",
    "idx2char[n_chars + 1] = \"UNK\"\n",
    "\n",
    "char2idx[\"PAD\"] = 0\n",
    "idx2char[0] = \"PAD\"\n",
    "\n",
    "# tag2idx[\"PAD\"] = 0\n",
    "# idx2tag[0] = \"PAD\"\n",
    "\n",
    "\n",
    "assert len(word2idx) == len(idx2word) and len(char2idx) == len(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 1, 'I': 2, 'B': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx = {i:x for x, i in enumerate(tag2idx.keys())}\n",
    "idx2tag = {i:x for x, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'O': 0, 'I': 1, 'B': 2}, {0: 'O', 1: 'I', 2: 'B'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx, idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10820 unique words/elements in the corpus being considered\n"
     ]
    }
   ],
   "source": [
    "n_words = len(word2idx)\n",
    "n_chars = len(char2idx)\n",
    "\n",
    "print(\"There are {} unique words/elements in the corpus being considered\".format(n_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience let us create a Pandas df summarising all the relevant data to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Sentence\", \"Labels\", \"Word Tokens\", \"Label Tokens\", \"Character Tokens\"]\n",
    "\n",
    "data_df = []\n",
    "for i in range(len(data)):\n",
    "    #We want data in the form : [Sentence, Labels, Words Tokens, Label Tokens]\n",
    "    sentence = data[i]['sentence']\n",
    "    labels = data[i]['entities']\n",
    "    words = sentence.split()\n",
    "    chars = [list(i) for i in words]\n",
    "    word_tkns = [word2idx.get(i) for i in words]\n",
    "    label_tkns = [tag2idx.get(i) for i in labels]\n",
    "    char_tkns = [list(map(char2idx.get, i)) for i in chars]\n",
    "    \n",
    "    data_df.append([sentence, labels, word_tkns, label_tkns, char_tkns])\n",
    "    \n",
    "data_df = pd.DataFrame(data_df, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Word Tokens</th>\n",
       "      <th>Label Tokens</th>\n",
       "      <th>Character Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identification of APC2 , a homologue of the ad...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B, I, I, I, O, O]</td>\n",
       "      <td>[777, 3, 2888, 4, 8, 778, 3, 2, 335, 280, 532,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0]</td>\n",
       "      <td>[[37, 11, 1, 4, 6, 2, 20, 2, 10, 3, 6, 2, 5, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The adenomatous polyposis coli ( APC ) tumour ...</td>\n",
       "      <td>[O, B, I, I, I, I, I, I, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[18, 335, 280, 532, 10, 115, 9, 507, 6, 355, 3...</td>\n",
       "      <td>[0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[34, 17, 1], [3, 11, 1, 4, 5, 13, 3, 6, 5, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex formation induces the rapid degradatio...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[4814, 623, 3363, 2, 1036, 2889, 3, 3362, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[24, 5, 13, 12, 9, 1, 32], [20, 5, 7, 13, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In colon carcinoma cells , loss of APC leads t...</td>\n",
       "      <td>[O, B, I, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[51, 1577, 578, 84, 4, 160, 3, 115, 872, 11, 2...</td>\n",
       "      <td>[0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[37, 4], [10, 5, 9, 5, 4], [10, 3, 7, 10, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Here , we report the identification and genomi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[368, 4, 54, 149, 2, 397, 7, 197, 517, 3, 115,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[[43, 1, 7, 1], [63], [44, 1], [7, 1, 12, 5, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  Identification of APC2 , a homologue of the ad...   \n",
       "1  The adenomatous polyposis coli ( APC ) tumour ...   \n",
       "2  Complex formation induces the rapid degradatio...   \n",
       "3  In colon carcinoma cells , loss of APC leads t...   \n",
       "4  Here , we report the identification and genomi...   \n",
       "\n",
       "                                              Labels  \\\n",
       "0         [O, O, O, O, O, O, O, O, B, I, I, I, O, O]   \n",
       "1  [O, B, I, I, I, I, I, I, O, O, O, O, O, O, O, ...   \n",
       "2                        [O, O, O, O, O, O, O, O, O]   \n",
       "3  [O, B, I, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "4            [O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                         Word Tokens  \\\n",
       "0  [777, 3, 2888, 4, 8, 778, 3, 2, 335, 280, 532,...   \n",
       "1  [18, 335, 280, 532, 10, 115, 9, 507, 6, 355, 3...   \n",
       "2       [4814, 623, 3363, 2, 1036, 2889, 3, 3362, 1]   \n",
       "3  [51, 1577, 578, 84, 4, 160, 3, 115, 872, 11, 2...   \n",
       "4  [368, 4, 54, 149, 2, 397, 7, 197, 517, 3, 115,...   \n",
       "\n",
       "                                        Label Tokens  \\\n",
       "0         [0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0]   \n",
       "1  [0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                    Character Tokens  \n",
       "0  [[37, 11, 1, 4, 6, 2, 20, 2, 10, 3, 6, 2, 5, 4...  \n",
       "1  [[34, 17, 1], [3, 11, 1, 4, 5, 13, 3, 6, 5, 14...  \n",
       "2  [[24, 5, 13, 12, 9, 1, 32], [20, 5, 7, 13, 3, ...  \n",
       "3  [[37, 4], [10, 5, 9, 5, 4], [10, 3, 7, 10, 2, ...  \n",
       "4  [[43, 1, 7, 1], [63], [44, 1], [7, 1, 12, 5, 7...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels = [i for x in data_df[\"Labels\"].values for i in x]\n",
    "cnt = Counter(labels)\n",
    "plt.bar(cnt.keys(), cnt.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    7287.000000\n",
       "mean       25.273364\n",
       "std        12.583760\n",
       "min         2.000000\n",
       "25%        17.000000\n",
       "50%        23.000000\n",
       "75%        32.000000\n",
       "max       123.000000\n",
       "Name: Word Tokens, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = data_df['Word Tokens'].map(len)\n",
    "\n",
    "lengths.hist()\n",
    "plt.show()\n",
    "\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    184167.000000\n",
       "mean          4.682104\n",
       "std           3.334064\n",
       "min           1.000000\n",
       "25%           2.000000\n",
       "50%           4.000000\n",
       "75%           7.000000\n",
       "max          26.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = data_df[\"Character Tokens\"]\n",
    "word_lengths = pd.Series([len(x) for i in words for x in i])\n",
    "\n",
    "word_lengths.hist()\n",
    "plt.show()\n",
    "\n",
    "word_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CHAR = 26\n",
    "MAX_WORD = 123\n",
    "\n",
    "padded_sentences = pad_sequences(data_df[\"Word Tokens\"], maxlen=MAX_WORD, dtype='int32', padding='post', truncating='post', value= word2idx[\"PAD\"])\n",
    "padded_labels = pad_sequences(data_df[\"Label Tokens\"], maxlen = MAX_WORD, dtype='int32', padding='post', truncating='post', value= tag2idx[\"O\"])\n",
    "padded_labels = np.array([to_categorical(i, num_classes = len(tag2idx)) for i in padded_labels])\n",
    "padded_chars = [pad_sequences(x, maxlen = MAX_CHAR, dtype = 'int32', padding = 'post', truncating = 'post', value= char2idx[\"PAD\"]) for x in data_df[\"Character Tokens\"]]\n",
    "padded_chars = pad_sequences(padded_chars, maxlen = MAX_WORD, padding = 'post', value = [0]*MAX_CHAR)\n",
    "\n",
    "no_samples = np.shape(padded_sentences)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(no_samples))\n",
    "\n",
    "train_idx, val_test_idx = train_test_split(idx, test_size = 0.6, shuffle = True, random_state = 2021)\n",
    "val_idx, test_idx = train_test_split(val_test_idx, test_size = 0.5)\n",
    "\n",
    "train_sent, train_chars, train_labels = padded_sentences[train_idx], padded_chars[train_idx], padded_labels[train_idx]\n",
    "val_sent, val_chars, val_labels = padded_sentences[val_idx], padded_chars[val_idx], padded_labels[val_idx]\n",
    "test_sent, test_chars, test_labels = padded_sentences[test_idx], padded_chars[test_idx], padded_labels[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(word_vocab_size, char_vocab_size, max_word_len, max_char_len, final_layer = 'softmax', lr = 0.001):\n",
    "    WORD_EMB_DIM = 64\n",
    "    CHAR_EMB_DIM = 64\n",
    "\n",
    "    # Input and Embedding for words\n",
    "    word_input = Input(shape = (max_word_len,))\n",
    "    word_emb = Embedding(input_dim=word_vocab_size + 1, output_dim=WORD_EMB_DIM, trainable = True,\n",
    "                         input_length=max_word_len, mask_zero = True, name = \"word_embed\")(word_input)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Input and Embedding for characters\n",
    "    char_input= Input(shape = (max_word_len, max_char_len,))\n",
    "    char_emb = TimeDistributed(Embedding(input_dim = char_vocab_size + 1, output_dim = CHAR_EMB_DIM, trainable = True,\n",
    "                                        input_length = max_char_len, name = \"char_embed\"))(char_input)\n",
    "    \n",
    "    \n",
    "    # Character CNN feature extraction with filter of length 3\n",
    "    char_conv = TimeDistributed(Conv1D(32, 4, padding='same'), name = \"td_conv1d\")(char_emb)\n",
    "    char_pool = TimeDistributed(GlobalMaxPooling1D(), name=\"char_pooling\")(char_conv)\n",
    "    \n",
    "    # Main LSTM\n",
    "    x = concatenate([word_emb, char_pool])\n",
    "    #x = SpatialDropout1D(0.3)(x)\n",
    "    main_lstm = Bidirectional(LSTM(units=32, return_sequences=True, dropout = 0.5, recurrent_dropout = 0.5), name = 'bilstm')(x)\n",
    "    \n",
    "    opt = Nadam(lr=lr, clipnorm = 1.0)\n",
    "    input_nodes = [word_input, char_input]\n",
    "    \n",
    "    if final_layer == 'softmax':\n",
    "        out = TimeDistributed(Dense(len(tag2idx), activation=\"softmax\"), name = 'tdd')(main_lstm)\n",
    "        model = Model(input_nodes, out)\n",
    "        #model.compile(loss = \"categorical_crossentropy\", optimizer=opt)\n",
    "    \n",
    "    elif final_layer == 'crf':\n",
    "        \n",
    "        crf = CRF(units = len(tag2idx))\n",
    "\n",
    "        out = crf(main_lstm)\n",
    "\n",
    "        model = Model(input_nodes, out)\n",
    "        #model = ModelWithCRFLoss(base_model, sparse_target=False)\n",
    "\n",
    "        #model.compile(optimizer=opt)\n",
    "    \n",
    "    try:\n",
    "        model.summary()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 123, 26)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 123, 26, 64)  5632        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 123)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "td_conv1d (TimeDistributed)     (None, 123, 26, 32)  8224        time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "word_embed (Embedding)          (None, 123, 64)      692544      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "char_pooling (TimeDistributed)  (None, 123, 32)      0           td_conv1d[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 123, 96)      0           word_embed[0][0]                 \n",
      "                                                                 char_pooling[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bilstm (Bidirectional)          (None, 123, 64)      33024       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf_1 (CRF)                     ((None, 123), (None, 212         bilstm[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 739,636\n",
      "Trainable params: 739,634\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = 'crf'\n",
    "\n",
    "model = get_model(len(word2idx), len(char2idx), MAX_WORD, MAX_CHAR, final_layer = classifier, lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.text.crf import crf_log_likelihood\n",
    "from typing import Union\n",
    "\n",
    "class ModelWithCRFLoss(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Wrapper around the base model for custom training logic.\n",
    "    Args:\n",
    "        base_model: The model including the CRF layer\n",
    "        sparse_target: if the y label is sparse or one-hot, default True\n",
    "        metric: the metric for training, default 'accuracy'. Warning: Currently tensorflow metrics like AUC need the output and y_true to be one-hot to cauculate, they are not supported.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_model, sparse_target=True, metric: Union[str, object] = 'accuracy'):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.sparse_target = sparse_target\n",
    "        self.metric = metric\n",
    "        if isinstance(metric, str):\n",
    "            if metric == 'accuracy':\n",
    "                self.metrics_fn = tf.keras.metrics.Accuracy(name='accuracy')\n",
    "            else:\n",
    "                raise ValueError('unknown metric name')\n",
    "        else:\n",
    "            self.metrics_fn = self.metric\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            return self.base_model(inputs)\n",
    "        else:\n",
    "            return self.base_model(inputs)[0]\n",
    "\n",
    "    def compute_loss(self, x, y, training=False):\n",
    "        viterbi_sequence, potentials, sequence_length, chain_kernel = self(x, training=training)\n",
    "        # we now add the CRF loss:\n",
    "        crf_loss = -crf_log_likelihood(potentials, y, sequence_length, chain_kernel)[0]\n",
    "        return viterbi_sequence, sequence_length, tf.reduce_mean(crf_loss)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y, sample_weight = unpack_data(data)\n",
    "        # y : '(batch_size, seq_length)'\n",
    "        if self.sparse_target:\n",
    "            assert len(y.shape) == 2\n",
    "        else:\n",
    "            y = tf.argmax(y, axis=-1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            viterbi_sequence, sequence_length, crf_loss = self.compute_loss(x, y, training=True)\n",
    "            loss = crf_loss + tf.cast(tf.reduce_sum(self.losses), crf_loss.dtype)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.metrics_fn.update_state(y, viterbi_sequence, tf.sequence_mask(sequence_length, y.shape[1]))\n",
    "        return {\"loss\": self.loss_tracker.result(), self.metrics_fn.name: self.metrics_fn.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.metrics_fn]\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y, sample_weight = unpack_data(data)\n",
    "        # y : '(batch_size, seq_length)'\n",
    "        if self.sparse_target:\n",
    "            assert len(y.shape) == 2\n",
    "        else:\n",
    "            y = tf.argmax(y, axis=-1)\n",
    "        viterbi_sequence, sequence_length, crf_loss = self.compute_loss(x, y, training=True)\n",
    "        loss = crf_loss + tf.cast(tf.reduce_sum(self.losses), crf_loss.dtype)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.metrics_fn.update_state(y, viterbi_sequence, tf.sequence_mask(sequence_length, y.shape[1]))\n",
    "        return self.loss_tracker.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_filepath = \"../docs/char_softmax.png\"\n",
    "\n",
    "plot_model(model, to_file = image_filepath, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_data(data):\n",
    "    if len(data) == 2:\n",
    "        return data[0], data[1], None\n",
    "    elif len(data) == 3:\n",
    "        return data\n",
    "    else:\n",
    "        raise TypeError(\"Expected data to be a tuple of size 2 or 3.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(sequence, size, shuffle = False):\n",
    "    seq = sequence.copy()\n",
    "    if shuffle == True:\n",
    "        random.shuffle(seq)\n",
    "    return [seq[pos:pos + size] for pos in range(0, len(seq), size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fit_crf(model, loss_fn, optimizer, metric, train_dataset, val_dataset, batch_size, epochs):\n",
    "    y = tf.argmax(y, axis=-1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        viterbi_sequence, sequence_length, crf_loss = self.compute_loss(x, y, training=True)\n",
    "        loss = crf_loss + tf.cast(tf.reduce_sum(self.losses), crf_loss.dtype)\n",
    "    gradients = tape.gradient(loss, self.trainable_variables)\n",
    "    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "    self.loss_tracker.update_state(loss)\n",
    "    self.metrics_fn.update_state(y, viterbi_sequence, tf.sequence_mask(sequence_length, y.shape[1]))\n",
    "    return {\"loss\": self.loss_tracker.result(), self.metrics_fn.name: self.metrics_fn.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fit(model, loss_fn, optimizer, metric, train_dataset, val_dataset, batch_size, epochs):\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(x_batch_train, y_batch_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        return loss_value\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(x_batch_val, y_batch_val):\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    \n",
    "    x_train, y_train = train_dataset\n",
    "    x_val, y_val = val_dataset\n",
    "    \n",
    "    train_acc_metric = metric\n",
    "    val_acc_metric = metric\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        train_indices = list(range(len(x_train[0])))\n",
    "        val_indices = list(range(len(x_val[0])))\n",
    "\n",
    "        train_batches = chunker(train_indices, batch_size)\n",
    "        val_batches = chunker(val_indices, batch_size)\n",
    "\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step, batch_indices in enumerate(train_batches):\n",
    "            batch_sents = x_train[0][batch_indices]\n",
    "            batch_chars = x_train[1][batch_indices]\n",
    "            \n",
    "            x_batch_train = [batch_sents, batch_chars]\n",
    "            y_batch_train = y_train[batch_indices]\n",
    "\n",
    "            loss_value = train_step(x_batch_train, y_batch_train)\n",
    "            \n",
    "            # Log every 200 batches.\n",
    "            if step % 200 == 0:\n",
    "                print(\n",
    "                    \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                    % (step, float(loss_value))\n",
    "                )\n",
    "                print(\"Seen so far: %d samples\" % ((step + 1) * 64))\n",
    "\n",
    "        # Display metrics at the end of each epoch.\n",
    "        train_acc = train_acc_metric.result()\n",
    "        print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "        # Reset training metrics at the end of each epoch\n",
    "        train_acc_metric.reset_states()\n",
    "\n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        for batch_indices in val_batches:\n",
    "            batch_sents = x_val[0][batch_indices]\n",
    "            batch_chars = x_val[1][batch_indices]\n",
    "            \n",
    "            x_batch_val = [batch_sents, batch_chars]\n",
    "            y_batch_val= y_val[batch_indices]\n",
    "\n",
    "            test_step(x_batch_val, y_batch_val)\n",
    "            \n",
    "        val_acc = val_acc_metric.result()\n",
    "        val_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 0.9474\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 30.77s\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.8797\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 24.97s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.8164\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 25.33s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.7637\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 26.16s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.7222\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 27.30s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.6905\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 27.56s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.6665\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 27.86s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.6481\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 27.53s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.6339\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.9829\n",
      "Validation acc: 0.9833\n",
      "Time taken: 25.21s\n"
     ]
    }
   ],
   "source": [
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "opt = Nadam(lr=0.001, clipnorm = 1.0)\n",
    "metric = keras.metrics.CategoricalAccuracy()\n",
    "train_dataset = ([train_sent, train_chars], train_labels)\n",
    "val_dataset = ([val_sent, val_chars], val_labels)\n",
    "epochs = 9\n",
    "batch_size = 16\n",
    "\n",
    "custom_fit(model, loss_fn, opt, metric, train_dataset, val_dataset, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "183/183 [==============================] - 42s 204ms/step - loss: 0.0966 - val_loss: 0.0404\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04037, saving model to ../saved_model_params/softmax.h5\n",
      "Epoch 2/15\n",
      " 36/183 [====>.........................] - ETA: 25s - loss: 0.0397"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-03ebd1067d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m history = model.fit(x = [train_sent, train_chars], y = train_labels, validation_data = ([val_sent, val_chars], val_labels),\n\u001b[0;32m---> 15\u001b[0;31m                    batch_size = BATCH_SIZE, epochs = MAX_EPOCHS, callbacks=[es, checkpoint, reduce_], verbose = 1)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_path = \"../saved_model_params/{}.h5\".format(classifier)\n",
    "BATCH_SIZE = 16\n",
    "MAX_EPOCHS = 15\n",
    "\n",
    "monitored_metric = \"val_loss\"\n",
    "\n",
    "if classifier == \"crf\":\n",
    "    monitored_metric += \"_val\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor=monitored_metric, verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor=monitored_metric, mode='min', verbose=1, patience=5)\n",
    "reduce_ = ReduceLROnPlateau(monitor=monitored_metric, mode='min', patience=3, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(x = [train_sent, train_chars], y = train_labels, validation_data = ([val_sent, val_chars], val_labels),\n",
    "                   batch_size = BATCH_SIZE, epochs = MAX_EPOCHS, callbacks=[es, checkpoint, reduce_], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[monitored_metric], label = \"Validation Loss\")\n",
    "plt.plot(history.history['loss'], label = \"Training Loss\")\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3e033acf1763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_chars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0mbase_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2593\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "loss = model.evaluate([test_sent, test_chars], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict([test_sent, test_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report([idx2tag[np.argmax(x)] for i in preds for x in i], [idx2tag[np.argmax(i)] for x in test_labels for i in x], labels = [\"B\", \"I\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 345\n",
    "if classifier == 'softmax':\n",
    "    p = np.argmax(preds[i], axis=-1)\n",
    "else:\n",
    "    p = preds[i]\n",
    "print(\"{:20}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(test_sent[i], np.argmax(test_labels[i], axis = -1), p):\n",
    "    if w != 0:\n",
    "        print(\"{:20}: {:5} {}\".format(idx2word[w], idx2tag[t], idx2tag[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Medical Transcription Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_trans = pd.read_csv(\"../data/mtsamples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_trans = med_trans.loc[med_trans['medical_specialty'] == \" Surgery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = surgery_trans['transcription'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER:\n",
    "    def __init__(self, text, classifier):\n",
    "        self.sent = text\n",
    "        self.classifier = classifier\n",
    "        self.preds = []\n",
    "        self.test_words = []\n",
    "        self.test_chars = []\n",
    "        \n",
    "    def build_data(self):\n",
    "        text = tokenize.sent_tokenize(self.sent)\n",
    "        word_tokens = []\n",
    "        char_tokens = []\n",
    "        for sent in text:\n",
    "            words = sent.split()\n",
    "            chars = [list(i) for i in words]\n",
    "            word_tkns = [word2idx.get(i, word2idx[\"UNK\"]) for i in words]\n",
    "            char_tkns = [list(map(lambda x: char2idx.get(x, char2idx[\"UNK\"]), i)) for i in chars]\n",
    "\n",
    "            word_tokens.append(word_tkns)\n",
    "            char_tokens.append(char_tkns)\n",
    "            \n",
    "        self.test_words = pad_sequences(word_tokens, maxlen=MAX_WORD, dtype='int32', padding='post', truncating='post', value= word2idx[\"PAD\"])\n",
    "        test_chars = [pad_sequences(x, maxlen = MAX_CHAR, dtype = 'int32', padding = 'post', truncating = 'post', value= char2idx[\"PAD\"]) for x in char_tokens]\n",
    "        self.test_chars = pad_sequences(test_chars, maxlen = MAX_WORD, padding = 'post', value = [0]*MAX_CHAR)\n",
    "        \n",
    "        return self.test_words, self.test_chars\n",
    "    \n",
    "    def predict(self):\n",
    "        if self.test_words == []:\n",
    "            self.build_data()\n",
    "        self.preds = model.predict([self.test_words, self.test_chars])\n",
    "        \n",
    "        return self.preds\n",
    "    \n",
    "    def pretty_print(self):\n",
    "        if self.preds == []:\n",
    "            self.predict()\n",
    "        preds = self.preds\n",
    "        text = tokenize.sent_tokenize(self.sent)\n",
    "        for x in range(len(preds)):\n",
    "            tag_preds = np.argmax(preds[x], axis=-1) if self.classifier != \"crf\" else preds[x]\n",
    "            test_sent = self.test_words[x]\n",
    "            true_words = text[x].split()\n",
    "            for i, (word, tag) in enumerate(zip(test_sent, tag_preds)):\n",
    "                if word != 0:\n",
    "                    if tag != 0:\n",
    "                        output = colored(true_words[i], color='green', on_color='on_grey')\n",
    "                    else:\n",
    "                        output = true_words[i]\n",
    "\n",
    "                    print(output, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NER(text[3], classifier)\n",
    "n.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
